{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47e027ba-17ec-4b1a-93a8-927dfd62e4f9",
   "metadata": {},
   "source": [
    "# Shapley calculations: Example III (GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0bd65d-632c-48db-b1fb-fb67283cb0c9",
   "metadata": {},
   "source": [
    ">NOTE I: The SHAP library has to be built from got rather than pip: ``pip install git+https://github.com/slundberg/shap.git``\n",
    "\n",
    ">NOTE II: The scikit model can not be built using max_depth > 31 for it to work with this code. You can set this in the SImBA config under  [create ensemble settings][rf_max_depth].\n",
    "\n",
    "In this example, we have previously created a classifier. We have the data used to create this classifier, and now we want to compute SHAP explainability scores\n",
    "for this classifier using GPU (to speed things up a MASSIVELY).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d37811de-7208-4753-af63-fab9e986ecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simba.sandbox.create_shap_log import create_shap_log\n",
    "from simba.mixins.train_model_mixin import TrainModelMixin\n",
    "from simba.mixins.config_reader import ConfigReader\n",
    "from simba.utils.read_write import read_df, read_config_file\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ee1e26e-fb8b-40a7-81a8-be5bfb80662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINITIONS\n",
    "CONFIG_PATH = r\"/mnt/c/troubleshooting/mitra/project_folder/project_config.ini\"\n",
    "CLASSIFIER_PATH = r\"/mnt/c/troubleshooting/mitra/models/generated_models/grooming.sav\"\n",
    "CLASSIFIER_NAME = 'grooming'\n",
    "SAVE_DIR = r'/mnt/c/troubleshooting/mitra/models/generated_models'\n",
    "COUNT_PRESENT = 50\n",
    "COUNT_ABSENT = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d5920c2-f7d3-4835-88b3-edc9459c3090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ IN THE CONFIG AND THE CLASSIFIER\n",
    "config = read_config_file(config_path=CONFIG_PATH)\n",
    "config_object = ConfigReader(config_path=CONFIG_PATH, create_logger=False)\n",
    "clf = read_df(file_path=CLASSIFIER_PATH, file_type='pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9ad6e27-a1c9-4a47-84cc-e6c7bef64517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading complete 842_MA42_gq_Saline_0621 (elapsed time: 1.6263s)...\n",
      "Reading complete 842_MA42_gq_CNO_0624 (elapsed time: 1.6594s)...\n",
      "Reading complete 501_MA142_Gi_CNO_0514 (elapsed time: 1.6711s)...\n",
      "Reading complete 592_MA147_Gq_CNO_0517 (elapsed time: 1.6725s)...\n",
      "Dataset size: 311.05188MB / 0.311052GB\n"
     ]
    }
   ],
   "source": [
    "# READ IN THE DATA\n",
    "\n",
    "#Read in the path to all files inside the project_folder/csv/targets_inserted directory\n",
    "file_paths = glob.glob(config_object.targets_folder + '/*' + config_object.file_type)\n",
    "#Reads in the data held in all files in ``file_paths`` defined above\n",
    "data, _ = TrainModelMixin().read_all_files_in_folder_mp(file_paths=file_paths, file_type=config.get('General settings', 'workflow_file_type').strip())\n",
    "#We find all behavior annotations that are NOT the targets. I.e., if SHAP values for Attack is going to be calculated, bit we need to find which other annotations exist in the data e.g., Escape and Defensive.\n",
    "non_target_annotations = TrainModelMixin().read_in_all_model_names_to_remove(config=config, model_cnt=config_object.clf_cnt, clf_name=CLASSIFIER_NAME)\n",
    "# We remove the body-part coordinate columns and the annotations which are not the target from the data\n",
    "data = data.drop(non_target_annotations + config_object.bp_headers, axis=1)\n",
    "# We place the target data in its own variable\n",
    "target_df = data.pop(CLASSIFIER_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66b8ea0-4699-41f8-b825-7f672b7387d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing SHAP values (GPU)...\n"
     ]
    }
   ],
   "source": [
    "#TO RETURN THE DATA\n",
    "\n",
    "shap_values, raw_values, expected_value = create_shap_log(rf_clf=clf,\n",
    "                                                          x=data,\n",
    "                                                          y=target_df,\n",
    "                                                          cnt_present=COUNT_PRESENT,\n",
    "                                                          cnt_absent=COUNT_ABSENT,\n",
    "                                                          x_names=list(data.columns),\n",
    "                                                          clf_name='grooming',\n",
    "                                                          save_dir=None,\n",
    "                                                          verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f0edc7-25a9-4009-9d33-eb53e39ae949",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simba_310",
   "language": "python",
   "name": "simba_310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
